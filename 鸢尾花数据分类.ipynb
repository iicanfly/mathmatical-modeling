{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "60\n",
      "[0 2 2 2 1 0 1 2 0 1 1 0 0 1 2 1 2 0 1 1 0 1 2 0 2 2 1 2 1 0 0 1 2 1 0 2 0\n",
      " 1 1 1 2 0 1 1 0 2 2 0 2 1 2 2 2 1 0 1 2 0 1 1]\n",
      "[0 2 2 2 1 0 1 2 0 1 1 0 0 1 2 1 2 0 1 1 0 2 2 0 2 2 1 2 1 0 0 1 2 1 0 1 0\n",
      " 1 1 1 2 0 1 1 0 2 2 0 2 1 2 2 2 1 0 1 2 0 2 1]\n",
      "57/60\n"
     ]
    }
   ],
   "source": [
    "#knn不降维\n",
    "from sklearn import datasets\n",
    "import random\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "#print(iris)\n",
    "data = iris['data']\n",
    "label = iris['target']\n",
    "num = label.size\n",
    "zipp = zip(data,label)\n",
    "zipp = list(zipp)\n",
    "#print(zipp)\n",
    "random.shuffle(zipp)\n",
    "train = zipp[0:90]\n",
    "test = zipp[90:150]\n",
    "print(len(train))\n",
    "print(len(test))\n",
    "\n",
    "train = zip(*train)\n",
    "train = list(train)\n",
    "test = zip(*test)\n",
    "test = list(test)\n",
    "#print(train)\n",
    "#print('=======')\n",
    "#print(test)\n",
    "\n",
    "train_d = list(train[0])\n",
    "train_t = np.array(list(train[1]))\n",
    "test_d = list(test[0])\n",
    "test_t = np.array(list(test[1]))\n",
    "\n",
    "ss = StandardScaler()\n",
    "zscore = ss.fit(train_d)\n",
    "train_d = zscore.transform(train_d)\n",
    "test_d = zscore.transform(test_d)\n",
    "knc = KNeighborsClassifier()\n",
    "knc.fit(train_d,train_t)\n",
    "y_predict = knc.predict(test_d)\n",
    "\n",
    "acc = 0\n",
    "\n",
    "print(y_predict)\n",
    "print(test_t)\n",
    "\n",
    "for i in range(60):\n",
    "    if(y_predict[i] == test_t[i]): acc += 1\n",
    "print('{}/{}'.format(acc,60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "60\n",
      "[0 1 2 1 2 0 1 2 0 1 1 0 0 1 2 1 2 0 1 1 0 1 1 0 1 2 1 2 2 0 0 1 1 1 0 2 0\n",
      " 1 1 1 2 0 1 1 0 2 2 0 2 1 2 2 1 1 0 1 2 0 1 2]\n",
      "[0 2 2 2 1 0 1 2 0 1 1 0 0 1 2 1 2 0 1 1 0 2 2 0 2 2 1 2 1 0 0 1 2 1 0 1 0\n",
      " 1 1 1 2 0 1 1 0 2 2 0 2 1 2 2 2 1 0 1 2 0 2 1]\n",
      "48/60\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#knn降为2唯\n",
    "from sklearn import datasets\n",
    "import random\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import PCA \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "train = zipp[0:90]\n",
    "test = zipp[90:150]\n",
    "print(len(train))\n",
    "print(len(test))\n",
    "\n",
    "train = zip(*train)\n",
    "train = list(train)\n",
    "test = zip(*test)\n",
    "test = list(test)\n",
    "#print(train)\n",
    "#print('=======')\n",
    "#print(test)\n",
    "\n",
    "train_d = list(train[0])\n",
    "train_t = np.array(list(train[1]))\n",
    "test_d = list(test[0])\n",
    "test_t = np.array(list(test[1]))\n",
    "\n",
    "ss = StandardScaler()\n",
    "zscore = ss.fit(train_d)\n",
    "train_d = zscore.transform(train_d)\n",
    "test_d = zscore.transform(test_d)\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "reduced_train_d = pca.fit_transform(train_d)\n",
    "reduced_test_d = pca.transform(test_d)\n",
    "\n",
    "knc = KNeighborsClassifier()\n",
    "knc.fit(reduced_train_d,train_t)\n",
    "y_predict = knc.predict(reduced_test_d)\n",
    "\n",
    "acc = 0\n",
    "\n",
    "print(y_predict)\n",
    "print(test_t)\n",
    "\n",
    "for i in range(60):\n",
    "    if(y_predict[i] == test_t[i]): acc += 1\n",
    "print('{}/{}'.format(acc,60))\n",
    "\n",
    "for i in range(90):\n",
    "    if(train_t[i] == 0):\n",
    "        plt.scatter(train_d[i][0],train_d[i][1],c='r',marker='o')\n",
    "    elif(train_t[i] == 1):\n",
    "        plt.scatter(train_d[i][0],train_d[i][1],c='g',marker='x')\n",
    "    elif(train_t[i] == 2):\n",
    "        plt.scatter(train_d[i][0],train_d[i][1],c='b',marker='s')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "60\n",
      "[ 1.         -1.13064705 -1.42665407 -0.19440735 -0.15823503  1.27836275\n",
      "  1.61304222  0.2198061   0.17890797  2.03534184  0.27735204  0.22574665\n",
      "  0.03779422  0.03076205  0.02503832]\n",
      "[1 2 1 2 1 2 2 2 1 1 0 0 0 2 2 0 1 2 0 1 0 0 1 2 0 0 2 2 2 1 2 1 1 1 2 0 2\n",
      " 2 2 1 0 0 2 0 1 0 1 0 2 0 0 1 1 2 1 1 0 2 2 1]\n",
      "[1 2 1 2 2 2 2 2 1 1 0 0 0 2 2 0 1 2 0 2 0 0 1 2 0 0 2 2 2 1 2 1 1 1 2 0 2\n",
      " 2 2 1 0 0 2 0 2 0 2 0 2 0 0 1 1 2 1 1 0 2 2 2]\n",
      "55/60\n"
     ]
    }
   ],
   "source": [
    "#knn升维rbf\n",
    "from sklearn import datasets\n",
    "import random\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "train = zipp[0:90]\n",
    "test = zipp[90:150]\n",
    "print(len(train))\n",
    "print(len(test))\n",
    "\n",
    "train = zip(*train)\n",
    "train = list(train)\n",
    "test = zip(*test)\n",
    "test = list(test)\n",
    "#print(train)\n",
    "#print('=======')\n",
    "#print(test)\n",
    "\n",
    "train_d = list(train[0])\n",
    "train_t = np.array(list(train[1]))\n",
    "test_d = list(test[0])\n",
    "test_t = np.array(list(test[1]))\n",
    "\n",
    "ss = StandardScaler()\n",
    "zscore = ss.fit(train_d)\n",
    "train_d = zscore.transform(train_d)\n",
    "test_d = zscore.transform(test_d)\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "train_d_up = poly.fit_transform(train_d)\n",
    "test_d_up = poly.transform(test_d)\n",
    "\n",
    "print(train_d_up[0])\n",
    "\n",
    "knc = KNeighborsClassifier()\n",
    "knc.fit(train_d_up,train_t)\n",
    "y_predict = knc.predict(test_d_up)\n",
    "\n",
    "acc = 0\n",
    "\n",
    "print(y_predict)\n",
    "print(test_t)\n",
    "\n",
    "for i in range(60):\n",
    "    if(y_predict[i] == test_t[i]): acc += 1\n",
    "print('{}/{}'.format(acc,60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "60\n",
      "torch.FloatTensor\n",
      "epoch 0\n",
      "=====================================\n",
      "9/90\n",
      "5/60\n",
      "0 1.1255946159362793\n",
      "Parameter containing:\n",
      "tensor([[ 0.4175, -0.3420, -0.0565,  0.4897],\n",
      "        [ 0.0235, -0.3299, -0.1481,  0.1614],\n",
      "        [-0.2073,  0.4230,  0.4935,  0.4775]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1627, -0.4260, -0.4116], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "9/90\n",
      "6/60\n",
      "110 1.1181787252426147\n",
      "Parameter containing:\n",
      "tensor([[ 0.4065, -0.3309, -0.0676,  0.4787],\n",
      "        [ 0.0344, -0.3409, -0.1372,  0.1724],\n",
      "        [-0.1964,  0.4121,  0.5045,  0.4885]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1736, -0.4150, -0.4226], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "9/90\n",
      "7/60\n",
      "111 1.1181116104125977\n",
      "Parameter containing:\n",
      "tensor([[ 0.4064, -0.3308, -0.0677,  0.4786],\n",
      "        [ 0.0345, -0.3410, -0.1371,  0.1725],\n",
      "        [-0.1963,  0.4120,  0.5046,  0.4886]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1737, -0.4149, -0.4227], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "9/90\n",
      "8/60\n",
      "196 1.1124367713928223\n",
      "Parameter containing:\n",
      "tensor([[ 0.3978, -0.3223, -0.0762,  0.4701],\n",
      "        [ 0.0429, -0.3494, -0.1287,  0.1808],\n",
      "        [-0.1879,  0.4037,  0.5130,  0.4970]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1820, -0.4064, -0.4310], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "11/90\n",
      "9/60\n",
      "291 1.106152057647705\n",
      "Parameter containing:\n",
      "tensor([[ 0.3882, -0.3127, -0.0858,  0.4604],\n",
      "        [ 0.0521, -0.3589, -0.1194,  0.1900],\n",
      "        [-0.1786,  0.3946,  0.5223,  0.5063]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1911, -0.3969, -0.4402], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "11/90\n",
      "10/60\n",
      "294 1.1059545278549194\n",
      "Parameter containing:\n",
      "tensor([[ 0.3879, -0.3124, -0.0861,  0.4601],\n",
      "        [ 0.0523, -0.3591, -0.1191,  0.1903],\n",
      "        [-0.1783,  0.3943,  0.5225,  0.5066]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1914, -0.3966, -0.4405], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "11/90\n",
      "11/60\n",
      "307 1.1050994396209717\n",
      "Parameter containing:\n",
      "tensor([[ 0.3866, -0.3111, -0.0874,  0.4588],\n",
      "        [ 0.0536, -0.3604, -0.1179,  0.1916],\n",
      "        [-0.1771,  0.3930,  0.5238,  0.5078]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1926, -0.3953, -0.4418], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "12/90\n",
      "12/60\n",
      "351 1.1022138595581055\n",
      "Parameter containing:\n",
      "tensor([[ 0.3821, -0.3066, -0.0919,  0.4544],\n",
      "        [ 0.0578, -0.3648, -0.1136,  0.1958],\n",
      "        [-0.1728,  0.3889,  0.5281,  0.5121]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1967, -0.3908, -0.4460], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "12/90\n",
      "13/60\n",
      "364 1.1013636589050293\n",
      "Parameter containing:\n",
      "tensor([[ 0.3808, -0.3053, -0.0932,  0.4530],\n",
      "        [ 0.0590, -0.3661, -0.1124,  0.1970],\n",
      "        [-0.1715,  0.3876,  0.5293,  0.5134]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1979, -0.3895, -0.4473], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "14/90\n",
      "14/60\n",
      "429 1.0971308946609497\n",
      "Parameter containing:\n",
      "tensor([[ 0.3741, -0.2987, -0.0999,  0.4464],\n",
      "        [ 0.0652, -0.3724, -0.1061,  0.2032],\n",
      "        [-0.1653,  0.3816,  0.5356,  0.5196]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2039, -0.3830, -0.4535], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "14/90\n",
      "15/60\n",
      "438 1.0965467691421509\n",
      "Parameter containing:\n",
      "tensor([[ 0.3732, -0.2978, -0.1008,  0.4455],\n",
      "        [ 0.0661, -0.3733, -0.1053,  0.2040],\n",
      "        [-0.1644,  0.3807,  0.5364,  0.5205]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2047, -0.3821, -0.4543], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "15/90\n",
      "16/60\n",
      "468 1.0946043729782104\n",
      "Parameter containing:\n",
      "tensor([[ 0.3701, -0.2947, -0.1038,  0.4424],\n",
      "        [ 0.0689, -0.3763, -0.1024,  0.2069],\n",
      "        [-0.1616,  0.3780,  0.5393,  0.5234]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2075, -0.3791, -0.4572], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "15/90\n",
      "17/60\n",
      "480 1.0938292741775513\n",
      "Parameter containing:\n",
      "tensor([[ 0.3689, -0.2935, -0.1051,  0.4412],\n",
      "        [ 0.0700, -0.3774, -0.1013,  0.2080],\n",
      "        [-0.1604,  0.3769,  0.5405,  0.5245]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2086, -0.3778, -0.4583], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "24/90\n",
      "18/60\n",
      "681 1.0809862613677979\n",
      "Parameter containing:\n",
      "tensor([[ 0.3482, -0.2729, -0.1257,  0.4206],\n",
      "        [ 0.0885, -0.3970, -0.0823,  0.2266],\n",
      "        [-0.1415,  0.3588,  0.5594,  0.5436]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2261, -0.3576, -0.4771], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "24/90\n",
      "19/60\n",
      "688 1.080544114112854\n",
      "Parameter containing:\n",
      "tensor([[ 0.3475, -0.2722, -0.1264,  0.4199],\n",
      "        [ 0.0892, -0.3977, -0.0817,  0.2272],\n",
      "        [-0.1408,  0.3582,  0.5601,  0.5443]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2267, -0.3569, -0.4777], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "27/90\n",
      "20/60\n",
      "724 1.078273892402649\n",
      "Parameter containing:\n",
      "tensor([[ 0.3438, -0.2685, -0.1301,  0.4162],\n",
      "        [ 0.0925, -0.4012, -0.0783,  0.2305],\n",
      "        [-0.1375,  0.3551,  0.5634,  0.5476]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2297, -0.3532, -0.4811], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "27/90\n",
      "22/60\n",
      "732 1.0777705907821655\n",
      "Parameter containing:\n",
      "tensor([[ 0.3430, -0.2677, -0.1309,  0.4154],\n",
      "        [ 0.0932, -0.4020, -0.0776,  0.2312],\n",
      "        [-0.1368,  0.3544,  0.5642,  0.5484]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2303, -0.3524, -0.4818], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "29/90\n",
      "23/60\n",
      "755 1.0763256549835205\n",
      "Parameter containing:\n",
      "tensor([[ 0.3406, -0.2653, -0.1333,  0.4130],\n",
      "        [ 0.0953, -0.4042, -0.0754,  0.2333],\n",
      "        [-0.1346,  0.3524,  0.5663,  0.5505]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2322, -0.3501, -0.4839], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "30/90\n",
      "24/60\n",
      "759 1.0760747194290161\n",
      "Parameter containing:\n",
      "tensor([[ 0.3402, -0.2649, -0.1337,  0.4126],\n",
      "        [ 0.0956, -0.4046, -0.0751,  0.2337],\n",
      "        [-0.1343,  0.3520,  0.5667,  0.5509]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2326, -0.3497, -0.4843], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "30/90\n",
      "25/60\n",
      "776 1.0750094652175903\n",
      "Parameter containing:\n",
      "tensor([[ 0.3384, -0.2632, -0.1354,  0.4108],\n",
      "        [ 0.0971, -0.4063, -0.0735,  0.2352],\n",
      "        [-0.1327,  0.3506,  0.5683,  0.5525]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2339, -0.3480, -0.4858], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "30/90\n",
      "26/60\n",
      "778 1.0748845338821411\n",
      "Parameter containing:\n",
      "tensor([[ 0.3382, -0.2630, -0.1356,  0.4106],\n",
      "        [ 0.0973, -0.4064, -0.0733,  0.2354],\n",
      "        [-0.1325,  0.3504,  0.5685,  0.5527]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2341, -0.3478, -0.4860], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "30/90\n",
      "27/60\n",
      "788 1.0742590427398682\n",
      "Parameter containing:\n",
      "tensor([[ 0.3372, -0.2619, -0.1367,  0.4096],\n",
      "        [ 0.0982, -0.4074, -0.0724,  0.2363],\n",
      "        [-0.1316,  0.3495,  0.5694,  0.5536]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2349, -0.3468, -0.4869], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "30/90\n",
      "28/60\n",
      "794 1.073884129524231\n",
      "Parameter containing:\n",
      "tensor([[ 0.3365, -0.2613, -0.1373,  0.4090],\n",
      "        [ 0.0988, -0.4080, -0.0718,  0.2369],\n",
      "        [-0.1310,  0.3490,  0.5699,  0.5542]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2354, -0.3462, -0.4875], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "32/90\n",
      "29/60\n",
      "805 1.073197364807129\n",
      "Parameter containing:\n",
      "tensor([[ 0.3354, -0.2602, -0.1384,  0.4078],\n",
      "        [ 0.0997, -0.4091, -0.0708,  0.2378],\n",
      "        [-0.1300,  0.3481,  0.5710,  0.5552]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2363, -0.3450, -0.4885], requires_grad=True)\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================\n",
      "33/90\n",
      "30/60\n",
      "848 1.0705195665359497\n",
      "Parameter containing:\n",
      "tensor([[ 0.3309, -0.2558, -0.1429,  0.4034],\n",
      "        [ 0.1036, -0.4132, -0.0669,  0.2417],\n",
      "        [-0.1261,  0.3444,  0.5749,  0.5592]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2397, -0.3407, -0.4924], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "37/90\n",
      "31/60\n",
      "899 1.067359447479248\n",
      "Parameter containing:\n",
      "tensor([[ 0.3257, -0.2505, -0.1481,  0.3981],\n",
      "        [ 0.1081, -0.4181, -0.0622,  0.2462],\n",
      "        [-0.1214,  0.3401,  0.5796,  0.5639]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2436, -0.3355, -0.4971], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "37/90\n",
      "32/60\n",
      "909 1.0667420625686646\n",
      "Parameter containing:\n",
      "tensor([[ 0.3246, -0.2495, -0.1492,  0.3971],\n",
      "        [ 0.1090, -0.4191, -0.0613,  0.2471],\n",
      "        [-0.1205,  0.3393,  0.5805,  0.5648]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2444, -0.3345, -0.4980], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "38/90\n",
      "33/60\n",
      "919 1.0661245584487915\n",
      "Parameter containing:\n",
      "tensor([[ 0.3236, -0.2484, -0.1502,  0.3961],\n",
      "        [ 0.1099, -0.4200, -0.0604,  0.2480],\n",
      "        [-0.1196,  0.3385,  0.5814,  0.5657]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2452, -0.3335, -0.4989], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "39/90\n",
      "34/60\n",
      "931 1.065385103225708\n",
      "Parameter containing:\n",
      "tensor([[ 0.3223, -0.2472, -0.1514,  0.3948],\n",
      "        [ 0.1109, -0.4212, -0.0593,  0.2491],\n",
      "        [-0.1185,  0.3375,  0.5825,  0.5668]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2461, -0.3323, -0.5000], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "44/90\n",
      "35/60\n",
      "969 1.0630494356155396\n",
      "Parameter containing:\n",
      "tensor([[ 0.3184, -0.2433, -0.1554,  0.3909],\n",
      "        [ 0.1143, -0.4248, -0.0558,  0.2524],\n",
      "        [-0.1151,  0.3343,  0.5860,  0.5703]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2489, -0.3285, -0.5034], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "45/90\n",
      "36/60\n",
      "977 1.0625591278076172\n",
      "Parameter containing:\n",
      "tensor([[ 0.3176, -0.2425, -0.1562,  0.3901],\n",
      "        [ 0.1150, -0.4256, -0.0551,  0.2531],\n",
      "        [-0.1143,  0.3337,  0.5867,  0.5711]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2495, -0.3276, -0.5041], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "45/90\n",
      "37/60\n",
      "989 1.061824083328247\n",
      "Parameter containing:\n",
      "tensor([[ 0.3163, -0.2412, -0.1574,  0.3888],\n",
      "        [ 0.1160, -0.4268, -0.0540,  0.2542],\n",
      "        [-0.1133,  0.3327,  0.5878,  0.5722]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2504, -0.3264, -0.5052], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "46/90\n",
      "38/60\n",
      "999 1.0612123012542725\n",
      "Parameter containing:\n",
      "tensor([[ 0.3153, -0.2402, -0.1585,  0.3878],\n",
      "        [ 0.1169, -0.4277, -0.0531,  0.2551],\n",
      "        [-0.1124,  0.3319,  0.5887,  0.5731]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2511, -0.3254, -0.5061], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "47/90\n",
      "39/60\n",
      "1012 1.060417890548706\n",
      "Parameter containing:\n",
      "tensor([[ 0.3139, -0.2388, -0.1598,  0.3865],\n",
      "        [ 0.1180, -0.4290, -0.0519,  0.2562],\n",
      "        [-0.1112,  0.3308,  0.5899,  0.5743]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2520, -0.3241, -0.5073], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "52/90\n",
      "40/60\n",
      "1112 1.054343342781067\n",
      "Parameter containing:\n",
      "tensor([[ 0.3035, -0.2285, -0.1702,  0.3761],\n",
      "        [ 0.1267, -0.4385, -0.0429,  0.2649],\n",
      "        [-0.1022,  0.3228,  0.5989,  0.5834]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2590, -0.3140, -0.5162], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "58/90\n",
      "41/60\n",
      "1147 1.0522316694259644\n",
      "Parameter containing:\n",
      "tensor([[ 0.2999, -0.2249, -0.1738,  0.3725],\n",
      "        [ 0.1297, -0.4418, -0.0398,  0.2679],\n",
      "        [-0.0991,  0.3200,  0.6020,  0.5865]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2613, -0.3104, -0.5193], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "58/90\n",
      "42/60\n",
      "1150 1.052051305770874\n",
      "Parameter containing:\n",
      "tensor([[ 0.2996, -0.2246, -0.1741,  0.3722],\n",
      "        [ 0.1299, -0.4421, -0.0395,  0.2682],\n",
      "        [-0.0989,  0.3198,  0.6023,  0.5868]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2615, -0.3101, -0.5196], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "60/90\n",
      "43/60\n",
      "1166 1.0510891675949097\n",
      "Parameter containing:\n",
      "tensor([[ 0.2979, -0.2229, -0.1758,  0.3705],\n",
      "        [ 0.1313, -0.4437, -0.0381,  0.2696],\n",
      "        [-0.0974,  0.3185,  0.6037,  0.5882]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2625, -0.3085, -0.5210], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "62/90\n",
      "44/60\n",
      "1255 1.0457665920257568\n",
      "Parameter containing:\n",
      "tensor([[ 0.2886, -0.2137, -0.1850,  0.3613],\n",
      "        [ 0.1388, -0.4521, -0.0301,  0.2772],\n",
      "        [-0.0896,  0.3116,  0.6116,  0.5962]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2680, -0.2995, -0.5289], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "64/90\n",
      "45/60\n",
      "1296 1.0433307886123657\n",
      "Parameter containing:\n",
      "tensor([[ 0.2844, -0.2094, -0.1892,  0.3570],\n",
      "        [ 0.1423, -0.4560, -0.0265,  0.2807],\n",
      "        [-0.0860,  0.3085,  0.6152,  0.5999]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2704, -0.2953, -0.5326], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "71/90\n",
      "46/60\n",
      "1354 1.039903163909912\n",
      "Parameter containing:\n",
      "tensor([[ 0.2783, -0.2034, -0.1953,  0.3510],\n",
      "        [ 0.1471, -0.4615, -0.0214,  0.2856],\n",
      "        [-0.0809,  0.3041,  0.6203,  0.6050]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2736, -0.2894, -0.5377], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "73/90\n",
      "47/60\n",
      "1401 1.0371404886245728\n",
      "Parameter containing:\n",
      "tensor([[ 0.2734, -0.1985, -0.2001,  0.3461],\n",
      "        [ 0.1510, -0.4659, -0.0173,  0.2895],\n",
      "        [-0.0769,  0.3007,  0.6244,  0.6092]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2760, -0.2846, -0.5418], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "74/90\n",
      "48/60\n",
      "1416 1.0362616777420044\n",
      "Parameter containing:\n",
      "tensor([[ 0.2719, -0.1970, -0.2017,  0.3446],\n",
      "        [ 0.1523, -0.4673, -0.0160,  0.2908],\n",
      "        [-0.0756,  0.2995,  0.6258,  0.6105]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2768, -0.2831, -0.5431], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "74/90\n",
      "49/60\n",
      "1442 1.0347421169281006\n",
      "Parameter containing:\n",
      "tensor([[ 0.2692, -0.1942, -0.2044,  0.3419],\n",
      "        [ 0.1544, -0.4698, -0.0137,  0.2929],\n",
      "        [-0.0733,  0.2977,  0.6280,  0.6128]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2780, -0.2805, -0.5454], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "75/90\n",
      "50/60\n",
      "1495 1.03165602684021\n",
      "Parameter containing:\n",
      "tensor([[ 0.2636, -0.1887, -0.2099,  0.3364],\n",
      "        [ 0.1588, -0.4748, -0.0091,  0.2974],\n",
      "        [-0.0688,  0.2938,  0.6326,  0.6175]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2805, -0.2751, -0.5501], requires_grad=True)\n",
      "=====================================\n",
      "epoch 4000\n",
      "epoch 8000\n",
      "epoch 12000\n",
      "epoch 16000\n",
      "epoch 20000\n",
      "epoch 24000\n",
      "epoch 28000\n"
     ]
    }
   ],
   "source": [
    "#logistic不改动\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn import datasets\n",
    "import random\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import copy\n",
    "\n",
    "\n",
    "train = zipp[0:90]\n",
    "test = zipp[90:150]\n",
    "print(len(train))\n",
    "print(len(test))\n",
    "\n",
    "train = zip(*train)\n",
    "train = list(train)\n",
    "test = zip(*test)\n",
    "test = list(test)\n",
    "#print(train)\n",
    "#print('=======')\n",
    "#print(test)\n",
    "\n",
    "train_d = np.array(list(train[0]))\n",
    "train_t = np.array(list(train[1]))\n",
    "test_d = np.array(list(test[0]))\n",
    "test_t = np.array(list(test[1]))\n",
    "\n",
    "train_t1 = np.zeros([90,3])\n",
    "test_t1 = np.zeros([60,3])\n",
    "\n",
    "for i in range(90):\n",
    "    train_t1[i][train_t[i]] = 1\n",
    "    \n",
    "for i in range(60):\n",
    "    test_t1[i][test_t[i]] = 1\n",
    "    \n",
    "#print(test_t)\n",
    "#print(test_t1)\n",
    "\n",
    "ss = StandardScaler()\n",
    "zscore = ss.fit(train_d)\n",
    "train_d = zscore.transform(train_d)\n",
    "test_d = zscore.transform(test_d)\n",
    "\n",
    "feature_num = 4\n",
    "cluster_num = 3\n",
    "\n",
    "train_d = torch.from_numpy(train_d).float()\n",
    "train_t = torch.from_numpy(train_t).long()\n",
    "test_d = torch.from_numpy(test_d).float()\n",
    "test_t = torch.from_numpy(test_t).long()\n",
    "\n",
    "print(train_d.type())\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(feature_num,cluster_num),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "\n",
    "learning_rate = 0.0001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "m_acc = 0\n",
    "para = model.parameters()\n",
    "\n",
    "for t in range(30000):\n",
    "    \n",
    "    # 前向传播：通过像模型输入x计算预测的y\n",
    "    y_pred = model(train_d)\n",
    "\n",
    "    # 计算并打印loss\n",
    "    loss = loss_fn(y_pred, train_t)\n",
    "    acc = 0\n",
    "    m = torch.max(y_pred,1)\n",
    "    for j in range(90):\n",
    "        if(m[1][j] == train_t[j]): acc += 1\n",
    "            \n",
    "    \n",
    "    y_pred_test = model(test_d)\n",
    "    acc_test = 0\n",
    "    m_test = torch.max(y_pred_test,1)\n",
    "    for j in range(60):\n",
    "        if(m_test[1][j] == test_t[j]): acc_test += 1\n",
    "    if t%4000 == 0:\n",
    "        print('epoch',t)\n",
    "    if acc_test > m_acc:\n",
    "        m_acc = acc_test\n",
    "        print('=====================================')\n",
    "        print('{}/{}'.format(acc,90))\n",
    "        print('{}/{}'.format(acc_test,60))\n",
    "\n",
    "        print(t, loss.item())    \n",
    "        for i in model.parameters():\n",
    "            print(i)\n",
    "        \n",
    "        print('=====================================')    \n",
    "\n",
    "    # 在反向传播之前，使用optimizer将它要更新的所有张量的梯度清零(这些张量是模型可学习的权重)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 反向传播：根据模型的参数计算loss的梯度\n",
    "    loss.backward()\n",
    "\n",
    "    # 调用Optimizer的step函数使它所有参数更新\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "60\n",
      "torch.FloatTensor\n",
      "=====================================\n",
      "24/90\n",
      "9/60\n",
      "0 1.0911362171173096\n",
      "Parameter containing:\n",
      "tensor([[ 0.1500, -0.1396],\n",
      "        [ 0.4100, -0.2151],\n",
      "        [-0.0367,  0.4016]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.3080,  0.0419, -0.0376], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "29/90\n",
      "10/60\n",
      "115 1.0855871438980103\n",
      "Parameter containing:\n",
      "tensor([[ 0.1385, -0.1281],\n",
      "        [ 0.4215, -0.2265],\n",
      "        [-0.0252,  0.4130]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.3195,  0.0534, -0.0490], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "29/90\n",
      "11/60\n",
      "132 1.0847711563110352\n",
      "Parameter containing:\n",
      "tensor([[ 0.1368, -0.1264],\n",
      "        [ 0.4232, -0.2282],\n",
      "        [-0.0235,  0.4147]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.3211,  0.0551, -0.0507], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "32/90\n",
      "12/60\n",
      "185 1.082236647605896\n",
      "Parameter containing:\n",
      "tensor([[ 0.1315, -0.1211],\n",
      "        [ 0.4284, -0.2335],\n",
      "        [-0.0182,  0.4199]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.3263,  0.0604, -0.0560], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "32/90\n",
      "13/60\n",
      "190 1.0819982290267944\n",
      "Parameter containing:\n",
      "tensor([[ 0.1310, -0.1206],\n",
      "        [ 0.4289, -0.2340],\n",
      "        [-0.0177,  0.4204]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.3268,  0.0609, -0.0565], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "34/90\n",
      "14/60\n",
      "234 1.0799041986465454\n",
      "Parameter containing:\n",
      "tensor([[ 0.1266, -0.1162],\n",
      "        [ 0.4333, -0.2383],\n",
      "        [-0.0133,  0.4247]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.3311,  0.0652, -0.0608], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "34/90\n",
      "15/60\n",
      "235 1.0798569917678833\n",
      "Parameter containing:\n",
      "tensor([[ 0.1265, -0.1161],\n",
      "        [ 0.4334, -0.2384],\n",
      "        [-0.0132,  0.4248]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.3312,  0.0653, -0.0609], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "36/90\n",
      "16/60\n",
      "275 1.0779614448547363\n",
      "Parameter containing:\n",
      "tensor([[ 0.1225, -0.1121],\n",
      "        [ 0.4374, -0.2424],\n",
      "        [-0.0092,  0.4287]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.3350,  0.0693, -0.0648], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "37/90\n",
      "17/60\n",
      "305 1.0765444040298462\n",
      "Parameter containing:\n",
      "tensor([[ 0.1195, -0.1091],\n",
      "        [ 0.4403, -0.2453],\n",
      "        [-0.0063,  0.4316]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.3378,  0.0723, -0.0678], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "40/90\n",
      "18/60\n",
      "345 1.0746616125106812\n",
      "Parameter containing:\n",
      "tensor([[ 0.1155, -0.1050],\n",
      "        [ 0.4443, -0.2492],\n",
      "        [-0.0023,  0.4355]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.3416,  0.0762, -0.0717], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "41/90\n",
      "19/60\n",
      "374 1.0733017921447754\n",
      "Parameter containing:\n",
      "tensor([[ 0.1127, -0.1021],\n",
      "        [ 0.4472, -0.2521],\n",
      "        [ 0.0006,  0.4383]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.3443,  0.0791, -0.0745], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "42/90\n",
      "20/60\n",
      "382 1.0729272365570068\n",
      "Parameter containing:\n",
      "tensor([[ 0.1119, -0.1013],\n",
      "        [ 0.4479, -0.2529],\n",
      "        [ 0.0014,  0.4391]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.3450,  0.0799, -0.0753], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "42/90\n",
      "21/60\n",
      "400 1.072085976600647\n",
      "Parameter containing:\n",
      "tensor([[ 0.1101, -0.0995],\n",
      "        [ 0.4497, -0.2546],\n",
      "        [ 0.0032,  0.4408]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.3467,  0.0817, -0.0770], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "43/90\n",
      "22/60\n",
      "411 1.0715724229812622\n",
      "Parameter containing:\n",
      "tensor([[ 0.1090, -0.0984],\n",
      "        [ 0.4508, -0.2557],\n",
      "        [ 0.0043,  0.4419]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.3477,  0.0828, -0.0781], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "43/90\n",
      "23/60\n",
      "424 1.0709664821624756\n",
      "Parameter containing:\n",
      "tensor([[ 0.1077, -0.0971],\n",
      "        [ 0.4521, -0.2570],\n",
      "        [ 0.0055,  0.4431]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.3489,  0.0840, -0.0794], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "49/90\n",
      "24/60\n",
      "582 1.063669204711914\n",
      "Parameter containing:\n",
      "tensor([[ 0.0920, -0.0813],\n",
      "        [ 0.4676, -0.2723],\n",
      "        [ 0.0212,  0.4581]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.3629,  0.0996, -0.0946], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "49/90\n",
      "25/60\n",
      "637 1.061159372329712\n",
      "Parameter containing:\n",
      "tensor([[ 0.0866, -0.0758],\n",
      "        [ 0.4730, -0.2776],\n",
      "        [ 0.0266,  0.4633]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.3675,  0.1050, -0.0999], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "52/90\n",
      "27/60\n",
      "736 1.056681513786316\n",
      "Parameter containing:\n",
      "tensor([[ 0.0768, -0.0660],\n",
      "        [ 0.4826, -0.2871],\n",
      "        [ 0.0363,  0.4725]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.3755,  0.1147, -0.1093], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "53/90\n",
      "28/60\n",
      "813 1.0532351732254028\n",
      "Parameter containing:\n",
      "tensor([[ 0.0693, -0.0583],\n",
      "        [ 0.4901, -0.2944],\n",
      "        [ 0.0439,  0.4796]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.3813,  0.1222, -0.1166], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "54/90\n",
      "29/60\n",
      "897 1.0495120286941528\n",
      "Parameter containing:\n",
      "tensor([[ 0.0610, -0.0500],\n",
      "        [ 0.4983, -0.3024],\n",
      "        [ 0.0521,  0.4873]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.3873,  0.1303, -0.1245], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "54/90\n",
      "30/60\n",
      "900 1.0493799448013306\n",
      "Parameter containing:\n",
      "tensor([[ 0.0607, -0.0497],\n",
      "        [ 0.4986, -0.3027],\n",
      "        [ 0.0524,  0.4876]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.3875,  0.1306, -0.1248], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "61/90\n",
      "31/60\n",
      "1235 1.0349206924438477\n",
      "Parameter containing:\n",
      "tensor([[ 0.0280, -0.0167],\n",
      "        [ 0.5309, -0.3342],\n",
      "        [ 0.0850,  0.5175]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.4064,  0.1629, -0.1558], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "62/90\n",
      "32/60\n",
      "1388 1.028518557548523\n",
      "Parameter containing:\n",
      "tensor([[ 0.0131, -0.0018],\n",
      "        [ 0.5456, -0.3483],\n",
      "        [ 0.0997,  0.5308]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.4115,  0.1775, -0.1698], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "65/90\n",
      "33/60\n",
      "1722 1.0149543285369873\n",
      "Parameter containing:\n",
      "tensor([[-0.0191,  0.0303],\n",
      "        [ 0.5775, -0.3789],\n",
      "        [ 0.1318,  0.5591]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.4122,  0.2091, -0.1998], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "67/90\n",
      "34/60\n",
      "1800 1.0118623971939087\n",
      "Parameter containing:\n",
      "tensor([[-0.0266,  0.0378],\n",
      "        [ 0.5850, -0.3859],\n",
      "        [ 0.1392,  0.5656]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.4099,  0.2164, -0.2068], requires_grad=True)\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "#logistic降维\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn import datasets\n",
    "import random\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import copy\n",
    "\n",
    "\n",
    "train = zipp[0:90]\n",
    "test = zipp[90:150]\n",
    "print(len(train))\n",
    "print(len(test))\n",
    "\n",
    "train = zip(*train)\n",
    "train = list(train)\n",
    "test = zip(*test)\n",
    "test = list(test)\n",
    "#print(train)\n",
    "#print('=======')\n",
    "#print(test)\n",
    "\n",
    "train_d = np.array(list(train[0]))\n",
    "train_t = np.array(list(train[1]))\n",
    "test_d = np.array(list(test[0]))\n",
    "test_t = np.array(list(test[1]))\n",
    "\n",
    "train_t1 = np.zeros([90,3])\n",
    "test_t1 = np.zeros([60,3])\n",
    "\n",
    "for i in range(90):\n",
    "    train_t1[i][train_t[i]] = 1\n",
    "    \n",
    "for i in range(60):\n",
    "    test_t1[i][test_t[i]] = 1\n",
    "    \n",
    "#print(test_t)\n",
    "#print(test_t1)\n",
    "\n",
    "ss = StandardScaler()\n",
    "zscore = ss.fit(train_d)\n",
    "train_d = zscore.transform(train_d)\n",
    "test_d = zscore.transform(test_d)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "reduced_train_d = pca.fit_transform(train_d)\n",
    "reduced_test_d = pca.transform(test_d)\n",
    "\n",
    "feature_num = 2\n",
    "cluster_num = 3\n",
    "\n",
    "train_d = torch.from_numpy(reduced_train_d).float()\n",
    "train_t = torch.from_numpy(train_t).long()\n",
    "test_d = torch.from_numpy(reduced_test_d).float()\n",
    "test_t = torch.from_numpy(test_t).long()\n",
    "\n",
    "print(train_d.type())\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(feature_num,cluster_num),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "\n",
    "learning_rate = 0.0001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "m_acc = 0\n",
    "para = model.parameters()\n",
    "\n",
    "for t in range(30000):\n",
    "    \n",
    "    # 前向传播：通过像模型输入x计算预测的y\n",
    "    y_pred = model(train_d)\n",
    "\n",
    "    # 计算并打印loss\n",
    "    loss = loss_fn(y_pred, train_t)\n",
    "    acc = 0\n",
    "    m = torch.max(y_pred,1)\n",
    "    for j in range(90):\n",
    "        if(m[1][j] == train_t[j]): acc += 1\n",
    "            \n",
    "    \n",
    "    y_pred_test = model(test_d)\n",
    "    acc_test = 0\n",
    "    m_test = torch.max(y_pred_test,1)\n",
    "    for j in range(60):\n",
    "        if(m_test[1][j] == test_t[j]): acc_test += 1\n",
    "    \n",
    "    if acc_test > m_acc:\n",
    "        m_acc = acc_test\n",
    "        print('=====================================')\n",
    "        print('{}/{}'.format(acc,90))\n",
    "        print('{}/{}'.format(acc_test,60))\n",
    "\n",
    "        print(t, loss.item())    \n",
    "        for i in model.parameters():\n",
    "            print(i)\n",
    "        \n",
    "        print('=====================================')    \n",
    "\n",
    "    # 在反向传播之前，使用optimizer将它要更新的所有张量的梯度清零(这些张量是模型可学习的权重)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 反向传播：根据模型的参数计算loss的梯度\n",
    "    loss.backward()\n",
    "\n",
    "    # 调用Optimizer的step函数使它所有参数更新\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "60\n",
      "torch.FloatTensor\n",
      "=====================================\n",
      "20/90\n",
      "23/60\n",
      "0 1.0834370851516724\n",
      "Parameter containing:\n",
      "tensor([[ 0.1268,  0.0124, -0.0455, -0.0654,  0.0695,  0.0933,  0.2529, -0.2360,\n",
      "          0.1698,  0.2032,  0.0451, -0.0127,  0.0562,  0.1209,  0.1981],\n",
      "        [-0.2462, -0.1599,  0.0213, -0.1479,  0.2271,  0.1699,  0.1752, -0.0881,\n",
      "         -0.0881, -0.2074,  0.2189, -0.0687, -0.2294,  0.1327, -0.1390],\n",
      "        [-0.1891,  0.2039,  0.1253,  0.2394, -0.1718,  0.0356, -0.0370,  0.1648,\n",
      "          0.0132,  0.0027, -0.0943, -0.0765,  0.2120,  0.0849,  0.2419]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0173, -0.1051,  0.2493], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "21/90\n",
      "24/60\n",
      "33 1.0787858963012695\n",
      "Parameter containing:\n",
      "tensor([[ 0.1234,  0.0092, -0.0422, -0.0687,  0.0662,  0.0966,  0.2496, -0.2327,\n",
      "          0.1731,  0.2064,  0.0418, -0.0160,  0.0595,  0.1242,  0.2014],\n",
      "        [-0.2429, -0.1566,  0.0180, -0.1447,  0.2304,  0.1667,  0.1785, -0.0914,\n",
      "         -0.0914, -0.2041,  0.2222, -0.0654, -0.2327,  0.1294, -0.1423],\n",
      "        [-0.1924,  0.2072,  0.1220,  0.2427, -0.1685,  0.0323, -0.0336,  0.1615,\n",
      "          0.0099, -0.0006, -0.0910, -0.0731,  0.2087,  0.0816,  0.2386]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0208, -0.1018,  0.2460], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "21/90\n",
      "25/60\n",
      "39 1.0779460668563843\n",
      "Parameter containing:\n",
      "tensor([[ 0.1228,  0.0086, -0.0416, -0.0692,  0.0656,  0.0972,  0.2490, -0.2321,\n",
      "          0.1737,  0.2070,  0.0412, -0.0165,  0.0601,  0.1248,  0.2020],\n",
      "        [-0.2423, -0.1561,  0.0174, -0.1441,  0.2310,  0.1661,  0.1791, -0.0920,\n",
      "         -0.0920, -0.2035,  0.2227, -0.0648, -0.2333,  0.1289, -0.1429],\n",
      "        [-0.1930,  0.2078,  0.1214,  0.2433, -0.1679,  0.0317, -0.0330,  0.1609,\n",
      "          0.0093, -0.0012, -0.0904, -0.0725,  0.2081,  0.0810,  0.2380]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0214, -0.1012,  0.2454], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "21/90\n",
      "26/60\n",
      "41 1.0776665210723877\n",
      "Parameter containing:\n",
      "tensor([[ 0.1226,  0.0084, -0.0414, -0.0694,  0.0654,  0.0974,  0.2488, -0.2319,\n",
      "          0.1739,  0.2072,  0.0410, -0.0167,  0.0603,  0.1250,  0.2022],\n",
      "        [-0.2421, -0.1559,  0.0172, -0.1439,  0.2312,  0.1659,  0.1793, -0.0922,\n",
      "         -0.0922, -0.2033,  0.2229, -0.0646, -0.2335,  0.1287, -0.1431],\n",
      "        [-0.1932,  0.2080,  0.1212,  0.2435, -0.1677,  0.0315, -0.0328,  0.1607,\n",
      "          0.0091, -0.0015, -0.0902, -0.0723,  0.2079,  0.0808,  0.2378]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0216, -0.1010,  0.2452], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "21/90\n",
      "27/60\n",
      "48 1.0766894817352295\n",
      "Parameter containing:\n",
      "tensor([[ 0.1218,  0.0077, -0.0407, -0.0701,  0.0647,  0.0981,  0.2481, -0.2313,\n",
      "          0.1746,  0.2079,  0.0404, -0.0174,  0.0610,  0.1257,  0.2029],\n",
      "        [-0.2414, -0.1552,  0.0165, -0.1432,  0.2319,  0.1652,  0.1800, -0.0929,\n",
      "         -0.0929, -0.2026,  0.2236, -0.0639, -0.2341,  0.1280, -0.1438],\n",
      "        [-0.1939,  0.2087,  0.1204,  0.2442, -0.1670,  0.0308, -0.0321,  0.1600,\n",
      "          0.0084, -0.0022, -0.0895, -0.0716,  0.2072,  0.0801,  0.2371]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0224, -0.1003,  0.2445], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "32/90\n",
      "28/60\n",
      "135 1.0647624731063843\n",
      "Parameter containing:\n",
      "tensor([[ 0.1109, -0.0009, -0.0322, -0.0787,  0.0561,  0.1055,  0.2396, -0.2230,\n",
      "          0.1829,  0.2155,  0.0320, -0.0258,  0.0693,  0.1340,  0.2112],\n",
      "        [-0.2326, -0.1466,  0.0079, -0.1346,  0.2405,  0.1576,  0.1885, -0.1013,\n",
      "         -0.1014, -0.1937,  0.2315, -0.0557, -0.2426,  0.1195, -0.1524],\n",
      "        [-0.2026,  0.2176,  0.1110,  0.2531, -0.1581,  0.0222, -0.0232,  0.1513,\n",
      "         -0.0004, -0.0110, -0.0806, -0.0627,  0.1983,  0.0712,  0.2281]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0333, -0.0914,  0.2357], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "32/90\n",
      "29/60\n",
      "141 1.0639538764953613\n",
      "Parameter containing:\n",
      "tensor([[ 0.1101, -0.0015, -0.0316, -0.0793,  0.0555,  0.1060,  0.2390, -0.2224,\n",
      "          0.1835,  0.2159,  0.0314, -0.0264,  0.0699,  0.1345,  0.2117],\n",
      "        [-0.2320, -0.1460,  0.0073, -0.1340,  0.2410,  0.1572,  0.1891, -0.1018,\n",
      "         -0.1020, -0.1931,  0.2320, -0.0551, -0.2432,  0.1189, -0.1529],\n",
      "        [-0.2032,  0.2183,  0.1103,  0.2537, -0.1574,  0.0216, -0.0226,  0.1507,\n",
      "         -0.0010, -0.0116, -0.0800, -0.0620,  0.1977,  0.0706,  0.2274]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0341, -0.0908,  0.2351], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "32/90\n",
      "30/60\n",
      "149 1.0628787279129028\n",
      "Parameter containing:\n",
      "tensor([[ 0.1090, -0.0023, -0.0308, -0.0801,  0.0548,  0.1066,  0.2383, -0.2217,\n",
      "          0.1842,  0.2165,  0.0307, -0.0271,  0.0706,  0.1353,  0.2125],\n",
      "        [-0.2311, -0.1452,  0.0065, -0.1332,  0.2418,  0.1566,  0.1899, -0.1026,\n",
      "         -0.1027, -0.1923,  0.2327, -0.0544, -0.2440,  0.1181, -0.1537],\n",
      "        [-0.2041,  0.2191,  0.1094,  0.2546, -0.1566,  0.0208, -0.0218,  0.1499,\n",
      "         -0.0018, -0.0125, -0.0791, -0.0612,  0.1969,  0.0698,  0.2266]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0352, -0.0900,  0.2343], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "36/90\n",
      "31/60\n",
      "183 1.0583432912826538\n",
      "Parameter containing:\n",
      "tensor([[ 0.1043, -0.0055, -0.0275, -0.0834,  0.0515,  0.1089,  0.2351, -0.2186,\n",
      "          0.1873,  0.2190,  0.0276, -0.0303,  0.0737,  0.1384,  0.2156],\n",
      "        [-0.2277, -0.1419,  0.0031, -0.1299,  0.2451,  0.1541,  0.1931, -0.1058,\n",
      "         -0.1060, -0.1888,  0.2354, -0.0514, -0.2472,  0.1148, -0.1570],\n",
      "        [-0.2075,  0.2227,  0.1056,  0.2581, -0.1531,  0.0175, -0.0182,  0.1465,\n",
      "         -0.0051, -0.0160, -0.0756, -0.0576,  0.1934,  0.0663,  0.2231]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0399, -0.0865,  0.2309], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "38/90\n",
      "32/60\n",
      "186 1.0579460859298706\n",
      "Parameter containing:\n",
      "tensor([[ 0.1039, -0.0058, -0.0272, -0.0836,  0.0512,  0.1091,  0.2348, -0.2183,\n",
      "          0.1876,  0.2192,  0.0273, -0.0305,  0.0740,  0.1387,  0.2158],\n",
      "        [-0.2273, -0.1416,  0.0028, -0.1296,  0.2454,  0.1539,  0.1934, -0.1061,\n",
      "         -0.1062, -0.1885,  0.2357, -0.0511, -0.2475,  0.1146, -0.1573],\n",
      "        [-0.2078,  0.2230,  0.1052,  0.2584, -0.1528,  0.0172, -0.0179,  0.1462,\n",
      "         -0.0054, -0.0163, -0.0752, -0.0573,  0.1931,  0.0660,  0.2228]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0403, -0.0862,  0.2306], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "39/90\n",
      "33/60\n",
      "189 1.0575491189956665\n",
      "Parameter containing:\n",
      "tensor([[ 0.1035, -0.0061, -0.0269, -0.0839,  0.0509,  0.1092,  0.2345, -0.2181,\n",
      "          0.1879,  0.2194,  0.0270, -0.0308,  0.0743,  0.1389,  0.2161],\n",
      "        [-0.2270, -0.1413,  0.0025, -0.1293,  0.2457,  0.1537,  0.1937, -0.1064,\n",
      "         -0.1065, -0.1882,  0.2359, -0.0508, -0.2477,  0.1143, -0.1576],\n",
      "        [-0.2081,  0.2233,  0.1049,  0.2588, -0.1525,  0.0169, -0.0176,  0.1459,\n",
      "         -0.0057, -0.0166, -0.0749, -0.0570,  0.1928,  0.0657,  0.2224]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0407, -0.0859,  0.2303], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "42/90\n",
      "34/60\n",
      "199 1.0562288761138916\n",
      "Parameter containing:\n",
      "tensor([[ 0.1021, -0.0071, -0.0260, -0.0849,  0.0499,  0.1098,  0.2335, -0.2172,\n",
      "          0.1888,  0.2200,  0.0261, -0.0317,  0.0752,  0.1398,  0.2170],\n",
      "        [-0.2260, -0.1404,  0.0015, -0.1283,  0.2466,  0.1530,  0.1946, -0.1073,\n",
      "         -0.1075, -0.1871,  0.2367, -0.0499, -0.2487,  0.1133, -0.1585],\n",
      "        [-0.2091,  0.2243,  0.1037,  0.2598, -0.1514,  0.0160, -0.0165,  0.1449,\n",
      "         -0.0067, -0.0176, -0.0739, -0.0559,  0.1918,  0.0646,  0.2214]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0421, -0.0849,  0.2293], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "43/90\n",
      "35/60\n",
      "201 1.0559654235839844\n",
      "Parameter containing:\n",
      "tensor([[ 0.1018, -0.0073, -0.0258, -0.0851,  0.0497,  0.1099,  0.2334, -0.2170,\n",
      "          0.1890,  0.2202,  0.0259, -0.0319,  0.0754,  0.1400,  0.2172],\n",
      "        [-0.2258, -0.1402,  0.0013, -0.1281,  0.2468,  0.1529,  0.1948, -0.1075,\n",
      "         -0.1077, -0.1869,  0.2368, -0.0498, -0.2489,  0.1131, -0.1587],\n",
      "        [-0.2093,  0.2246,  0.1035,  0.2600, -0.1512,  0.0158, -0.0163,  0.1447,\n",
      "         -0.0069, -0.0178, -0.0737, -0.0557,  0.1916,  0.0644,  0.2212]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0424, -0.0847,  0.2291], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "48/90\n",
      "36/60\n",
      "214 1.0542577505111694\n",
      "Parameter containing:\n",
      "tensor([[ 9.9984e-02, -8.5224e-03, -2.4530e-02, -8.6331e-02,  4.8489e-02,\n",
      "          1.1066e-01,  2.3215e-01, -2.1586e-01,  1.9011e-01,  2.2098e-01,\n",
      "          2.4765e-02, -3.3090e-02,  7.6507e-02,  1.4117e-01,  2.1830e-01],\n",
      "        [-2.2446e-01, -1.3891e-01,  1.7202e-06, -1.2684e-01,  2.4808e-01,\n",
      "          1.5210e-01,  1.9606e-01, -1.0866e-01, -1.0888e-01, -1.8559e-01,\n",
      "          2.3779e-01, -4.8636e-02, -2.5008e-01,  1.1190e-01, -1.5996e-01],\n",
      "        [-2.1061e-01,  2.2593e-01,  1.0195e-01,  2.6139e-01, -1.4983e-01,\n",
      "          1.4531e-02, -1.4958e-02,  1.4346e-01, -8.1756e-03, -1.9188e-02,\n",
      "         -7.2290e-02, -5.4315e-02,  1.9025e-01,  6.3098e-02,  2.1986e-01]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0442, -0.0833,  0.2278], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "48/90\n",
      "37/60\n",
      "222 1.053210735321045\n",
      "Parameter containing:\n",
      "tensor([[ 0.0989, -0.0093, -0.0238, -0.0871,  0.0477,  0.1111,  0.2314, -0.2152,\n",
      "          0.1908,  0.2215,  0.0240, -0.0338,  0.0772,  0.1419,  0.2190],\n",
      "        [-0.2236, -0.1381, -0.0008, -0.1261,  0.2488,  0.1516,  0.1968, -0.1094,\n",
      "         -0.1096, -0.1848,  0.2384, -0.0479, -0.2508,  0.1111, -0.1607],\n",
      "        [-0.2114,  0.2268,  0.1010,  0.2622, -0.1490,  0.0138, -0.0141,  0.1427,\n",
      "         -0.0090, -0.0200, -0.0714, -0.0535,  0.1894,  0.0623,  0.2190]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0453, -0.0825,  0.2270], requires_grad=True)\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================\n",
      "51/90\n",
      "38/60\n",
      "900 0.9753207564353943\n",
      "Parameter containing:\n",
      "tensor([[ 0.0039, -0.0718,  0.0387, -0.1497, -0.0149,  0.0474,  0.1725, -0.1732,\n",
      "          0.2368,  0.1892, -0.0288, -0.0880,  0.1244,  0.1893,  0.2632],\n",
      "        [-0.1524, -0.0759, -0.0680, -0.0628,  0.3095,  0.1732,  0.2550, -0.1667,\n",
      "         -0.1693, -0.1132,  0.2448, -0.0018, -0.3100,  0.0502, -0.2228],\n",
      "        [-0.2759,  0.2989,  0.0261,  0.3338, -0.0778, -0.0311,  0.0536,  0.0940,\n",
      "         -0.0548, -0.0874, -0.0029,  0.0156,  0.1325,  0.0095,  0.2044]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1403, -0.0113,  0.1625], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "51/90\n",
      "39/60\n",
      "901 0.9752195477485657\n",
      "Parameter containing:\n",
      "tensor([[ 0.0037, -0.0719,  0.0388, -0.1498, -0.0150,  0.0472,  0.1724, -0.1732,\n",
      "          0.2368,  0.1891, -0.0288, -0.0880,  0.1245,  0.1894,  0.2632],\n",
      "        [-0.1523, -0.0759, -0.0681, -0.0627,  0.3096,  0.1733,  0.2551, -0.1667,\n",
      "         -0.1694, -0.1131,  0.2448, -0.0018, -0.3101,  0.0502, -0.2229],\n",
      "        [-0.2760,  0.2990,  0.0260,  0.3339, -0.0777, -0.0312,  0.0537,  0.0939,\n",
      "         -0.0549, -0.0875, -0.0028,  0.0157,  0.1325,  0.0095,  0.2045]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1404, -0.0112,  0.1624], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "52/90\n",
      "40/60\n",
      "936 0.9716961979866028\n",
      "Parameter containing:\n",
      "tensor([[-8.5293e-04, -7.5153e-02,  4.1974e-02, -1.5304e-01, -1.8243e-02,\n",
      "          4.1513e-02,  1.6939e-01, -1.7198e-01,  2.3849e-01,  1.8458e-01,\n",
      "         -3.1380e-02, -9.0680e-02,  1.2630e-01,  1.9124e-01,  2.6474e-01],\n",
      "        [-1.4864e-01, -7.2762e-02, -7.1512e-02, -5.9573e-02,  3.1256e-01,\n",
      "          1.7697e-01,  2.5777e-01, -1.6959e-01, -1.7239e-01, -1.0940e-01,\n",
      "          2.4237e-01,  7.6991e-05, -3.1302e-01,  4.7095e-02, -2.2601e-01],\n",
      "        [-2.7904e-01,  3.0251e-01,  2.2754e-02,  3.3744e-01, -7.4160e-02,\n",
      "         -3.2318e-02,  5.6730e-02,  9.2509e-02, -5.5901e-02, -9.0616e-02,\n",
      "          2.3658e-04,  1.8815e-02,  1.3040e-01,  7.9826e-03,  2.0832e-01]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1450, -0.0075,  0.1594], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "54/90\n",
      "41/60\n",
      "986 0.9667286276817322\n",
      "Parameter containing:\n",
      "tensor([[-0.0074, -0.0797,  0.0465, -0.1576, -0.0228,  0.0334,  0.1651, -0.1704,\n",
      "          0.2407,  0.1780, -0.0350, -0.0945,  0.1289,  0.1938,  0.2668],\n",
      "        [-0.1434, -0.0684, -0.0764, -0.0551,  0.3167,  0.1824,  0.2616, -0.1736,\n",
      "         -0.1767, -0.1042,  0.2385,  0.0026, -0.3172,  0.0427, -0.2305],\n",
      "        [-0.2834,  0.3075,  0.0183,  0.3424, -0.0692, -0.0338,  0.0610,  0.0906,\n",
      "         -0.0572, -0.0950,  0.0045,  0.0231,  0.1276,  0.0061,  0.2142]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1515, -0.0023,  0.1550], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "54/90\n",
      "42/60\n",
      "989 0.9664329290390015\n",
      "Parameter containing:\n",
      "tensor([[-0.0077, -0.0800,  0.0468, -0.1579, -0.0231,  0.0329,  0.1648, -0.1703,\n",
      "          0.2409,  0.1776, -0.0352, -0.0947,  0.1290,  0.1940,  0.2669],\n",
      "        [-0.1431, -0.0681, -0.0767, -0.0548,  0.3170,  0.1827,  0.2618, -0.1739,\n",
      "         -0.1769, -0.1038,  0.2383,  0.0028, -0.3175,  0.0425, -0.2308],\n",
      "        [-0.2837,  0.3078,  0.0180,  0.3427, -0.0689, -0.0339,  0.0612,  0.0905,\n",
      "         -0.0573, -0.0952,  0.0048,  0.0234,  0.1274,  0.0060,  0.2146]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1519, -0.0020,  0.1547], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "56/90\n",
      "43/60\n",
      "1069 0.9586454629898071\n",
      "Parameter containing:\n",
      "tensor([[-0.0180, -0.0874,  0.0540, -0.1653, -0.0305,  0.0201,  0.1580, -0.1683,\n",
      "          0.2441,  0.1669, -0.0411, -0.1007,  0.1329,  0.1979,  0.2699],\n",
      "        [-0.1347, -0.0611, -0.0846, -0.0477,  0.3236,  0.1917,  0.2677, -0.1804,\n",
      "         -0.1837, -0.0955,  0.2311,  0.0067, -0.3242,  0.0355, -0.2379],\n",
      "        [-0.2906,  0.3157,  0.0112,  0.3505, -0.0611, -0.0361,  0.0678,  0.0878,\n",
      "         -0.0591, -0.1021,  0.0115,  0.0301,  0.1232,  0.0033,  0.2250]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1622,  0.0064,  0.1478], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "66/90\n",
      "44/60\n",
      "1230 0.9435105323791504\n",
      "Parameter containing:\n",
      "tensor([[-0.0381, -0.1023,  0.0686, -0.1801, -0.0454, -0.0049,  0.1439, -0.1660,\n",
      "          0.2494,  0.1452, -0.0529, -0.1130,  0.1399,  0.2050,  0.2748],\n",
      "        [-0.1180, -0.0471, -0.1003, -0.0335,  0.3367,  0.2102,  0.2792, -0.1934,\n",
      "         -0.1974, -0.0788,  0.2141,  0.0140, -0.3378,  0.0214, -0.2523],\n",
      "        [-0.3044,  0.3311, -0.0017,  0.3657, -0.0458, -0.0398,  0.0803,  0.0832,\n",
      "         -0.0616, -0.1153,  0.0241,  0.0427,  0.1157, -0.0005,  0.2472]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1823,  0.0231,  0.1340], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "66/90\n",
      "45/60\n",
      "1259 0.9408565759658813\n",
      "Parameter containing:\n",
      "tensor([[-0.0417, -0.1050,  0.0712, -0.1828, -0.0480, -0.0092,  0.1414, -0.1658,\n",
      "          0.2502,  0.1413, -0.0550, -0.1152,  0.1410,  0.2061,  0.2755],\n",
      "        [-0.1150, -0.0447, -0.1031, -0.0309,  0.3390,  0.2135,  0.2812, -0.1958,\n",
      "         -0.1999, -0.0759,  0.2108,  0.0153, -0.3403,  0.0189, -0.2549],\n",
      "        [-0.3068,  0.3338, -0.0039,  0.3684, -0.0431, -0.0404,  0.0825,  0.0825,\n",
      "         -0.0620, -0.1176,  0.0263,  0.0448,  0.1145, -0.0010,  0.2512]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1859,  0.0261,  0.1315], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "66/90\n",
      "47/60\n",
      "1262 0.9405829310417175\n",
      "Parameter containing:\n",
      "tensor([[-0.0420, -0.1053,  0.0714, -0.1830, -0.0483, -0.0097,  0.1411, -0.1658,\n",
      "          0.2502,  0.1409, -0.0553, -0.1155,  0.1411,  0.2062,  0.2755],\n",
      "        [-0.1147, -0.0444, -0.1034, -0.0307,  0.3392,  0.2138,  0.2814, -0.1960,\n",
      "         -0.2001, -0.0756,  0.2104,  0.0154, -0.3405,  0.0186, -0.2552],\n",
      "        [-0.3071,  0.3341, -0.0041,  0.3687, -0.0429, -0.0405,  0.0827,  0.0824,\n",
      "         -0.0620, -0.1178,  0.0265,  0.0450,  0.1143, -0.0010,  0.2517]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1862,  0.0264,  0.1313], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "67/90\n",
      "48/60\n",
      "1321 0.9352537393569946\n",
      "Parameter containing:\n",
      "tensor([[-0.0492, -0.1107,  0.0767, -0.1885, -0.0538, -0.0185,  0.1359, -0.1657,\n",
      "          0.2516,  0.1331, -0.0597, -0.1200,  0.1433,  0.2085,  0.2768],\n",
      "        [-0.1086, -0.0393, -0.1091, -0.0255,  0.3439,  0.2206,  0.2854, -0.2008,\n",
      "         -0.2052, -0.0695,  0.2034,  0.0179, -0.3455,  0.0135, -0.2605],\n",
      "        [-0.3121,  0.3396, -0.0085,  0.3741, -0.0374, -0.0417,  0.0870,  0.0810,\n",
      "         -0.0626, -0.1225,  0.0308,  0.0493,  0.1119, -0.0018,  0.2599]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1934,  0.0325,  0.1263], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "68/90\n",
      "49/60\n",
      "1332 0.9342696070671082\n",
      "Parameter containing:\n",
      "tensor([[-0.0505, -0.1118,  0.0777, -0.1895, -0.0548, -0.0201,  0.1349, -0.1658,\n",
      "          0.2519,  0.1317, -0.0605, -0.1209,  0.1437,  0.2089,  0.2770],\n",
      "        [-0.1075, -0.0384, -0.1102, -0.0246,  0.3448,  0.2219,  0.2862, -0.2017,\n",
      "         -0.2061, -0.0684,  0.2021,  0.0184, -0.3465,  0.0125, -0.2614],\n",
      "        [-0.3130,  0.3406, -0.0093,  0.3751, -0.0364, -0.0419,  0.0878,  0.0808,\n",
      "         -0.0627, -0.1233,  0.0316,  0.0501,  0.1115, -0.0020,  0.2614]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1947,  0.0336,  0.1254], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "68/90\n",
      "50/60\n",
      "1341 0.9334666728973389\n",
      "Parameter containing:\n",
      "tensor([[-0.0516, -0.1126,  0.0785, -0.1903, -0.0557, -0.0214,  0.1341, -0.1658,\n",
      "          0.2521,  0.1305, -0.0612, -0.1216,  0.1441,  0.2092,  0.2771],\n",
      "        [-0.1066, -0.0376, -0.1111, -0.0238,  0.3455,  0.2229,  0.2868, -0.2024,\n",
      "         -0.2069, -0.0675,  0.2010,  0.0188, -0.3472,  0.0117, -0.2622],\n",
      "        [-0.3138,  0.3414, -0.0099,  0.3760, -0.0356, -0.0421,  0.0884,  0.0806,\n",
      "         -0.0628, -0.1240,  0.0323,  0.0507,  0.1111, -0.0021,  0.2627]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1958,  0.0346,  0.1246], requires_grad=True)\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================\n",
      "69/90\n",
      "51/60\n",
      "1420 0.9265018701553345\n",
      "Parameter containing:\n",
      "tensor([[-0.0610, -0.1200,  0.0856, -0.1977, -0.0630, -0.0328,  0.1271, -0.1663,\n",
      "          0.2535,  0.1202, -0.0671, -0.1278,  0.1468,  0.2120,  0.2783],\n",
      "        [-0.0985, -0.0309, -0.1187, -0.0169,  0.3517,  0.2318,  0.2919, -0.2089,\n",
      "         -0.2136, -0.0595,  0.1914,  0.0220, -0.3539,  0.0048, -0.2693],\n",
      "        [-0.3205,  0.3487, -0.0155,  0.3831, -0.0284, -0.0437,  0.0939,  0.0788,\n",
      "         -0.0635, -0.1301,  0.0378,  0.0562,  0.1082, -0.0027,  0.2735]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2052,  0.0427,  0.1179], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "69/90\n",
      "52/60\n",
      "1426 0.9259788393974304\n",
      "Parameter containing:\n",
      "tensor([[-0.0617, -0.1205,  0.0861, -0.1982, -0.0636, -0.0337,  0.1265, -0.1664,\n",
      "          0.2536,  0.1194, -0.0676, -0.1282,  0.1470,  0.2122,  0.2784],\n",
      "        [-0.0979, -0.0304, -0.1193, -0.0164,  0.3522,  0.2325,  0.2923, -0.2094,\n",
      "         -0.2141, -0.0589,  0.1906,  0.0223, -0.3544,  0.0043, -0.2698],\n",
      "        [-0.3210,  0.3492, -0.0159,  0.3836, -0.0278, -0.0438,  0.0943,  0.0787,\n",
      "         -0.0635, -0.1306,  0.0383,  0.0566,  0.1080, -0.0028,  0.2744]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2059,  0.0433,  0.1174], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "70/90\n",
      "53/60\n",
      "1513 0.9184921979904175\n",
      "Parameter containing:\n",
      "tensor([[-0.0718, -0.1286,  0.0939, -0.2063, -0.0717, -0.0459,  0.1187, -0.1676,\n",
      "          0.2547,  0.1083, -0.0743, -0.1351,  0.1498,  0.2149,  0.2792],\n",
      "        [-0.0890, -0.0231, -0.1277, -0.0090,  0.3589,  0.2422,  0.2978, -0.2165,\n",
      "         -0.2215, -0.0502,  0.1798,  0.0257, -0.3618, -0.0033, -0.2776],\n",
      "        [-0.3283,  0.3570, -0.0217,  0.3914, -0.0201, -0.0456,  0.1001,  0.0770,\n",
      "         -0.0641, -0.1371,  0.0441,  0.0623,  0.1050, -0.0030,  0.2861]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2160,  0.0521,  0.1101], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "76/90\n",
      "54/60\n",
      "2148 0.8693398237228394\n",
      "Parameter containing:\n",
      "tensor([[-0.1396, -0.1875,  0.1492, -0.2647, -0.1306, -0.1212,  0.0614, -0.1832,\n",
      "          0.2573,  0.0356, -0.1245, -0.1867,  0.1681,  0.2312,  0.2746],\n",
      "        [-0.0261,  0.0282, -0.1871,  0.0434,  0.4045,  0.3071,  0.3321, -0.2693,\n",
      "         -0.2757,  0.0103,  0.1027,  0.0489, -0.4163, -0.0587, -0.3341],\n",
      "        [-0.3815,  0.4106, -0.0577,  0.4449,  0.0340, -0.0617,  0.1360,  0.0661,\n",
      "         -0.0676, -0.1815,  0.0804,  0.0967,  0.0908,  0.0084,  0.3648]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2838,  0.1151,  0.0569], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "76/90\n",
      "55/60\n",
      "2293 0.8594984412193298\n",
      "Parameter containing:\n",
      "tensor([[-0.1537, -0.2006,  0.1615, -0.2777, -0.1438, -0.1348,  0.0489, -0.1851,\n",
      "          0.2587,  0.0210, -0.1358, -0.1983,  0.1732,  0.2351,  0.2720],\n",
      "        [-0.0121,  0.0393, -0.2002,  0.0548,  0.4141,  0.3209,  0.3386, -0.2814,\n",
      "         -0.2880,  0.0233,  0.0864,  0.0543, -0.4287, -0.0713, -0.3469],\n",
      "        [-0.3937,  0.4222, -0.0648,  0.4566,  0.0458, -0.0665,  0.1428,  0.0640,\n",
      "         -0.0686, -0.1911,  0.0872,  0.1028,  0.0894,  0.0142,  0.3813]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2979,  0.1290,  0.0447], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "76/90\n",
      "56/60\n",
      "2319 0.8577858209609985\n",
      "Parameter containing:\n",
      "tensor([[-0.1562, -0.2029,  0.1637, -0.2800, -0.1462, -0.1372,  0.0467, -0.1854,\n",
      "          0.2591,  0.0185, -0.1378, -0.2003,  0.1741,  0.2358,  0.2715],\n",
      "        [-0.0096,  0.0413, -0.2025,  0.0569,  0.4158,  0.3234,  0.3397, -0.2836,\n",
      "         -0.2902,  0.0257,  0.0836,  0.0553, -0.4310, -0.0736, -0.3492],\n",
      "        [-0.3959,  0.4242, -0.0660,  0.4587,  0.0479, -0.0674,  0.1440,  0.0636,\n",
      "         -0.0688, -0.1928,  0.0884,  0.1038,  0.0892,  0.0153,  0.3842]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.3004,  0.1315,  0.0425], requires_grad=True)\n",
      "=====================================\n",
      "=====================================\n",
      "84/90\n",
      "57/60\n",
      "2985 0.8186906576156616\n",
      "Parameter containing:\n",
      "tensor([[-0.2173, -0.2602,  0.2188, -0.3376, -0.2046, -0.1887, -0.0057, -0.1786,\n",
      "          0.2763, -0.0419, -0.1860, -0.2500,  0.2028,  0.2564,  0.2546],\n",
      "        [ 0.0524,  0.0901, -0.2603,  0.1070,  0.4557,  0.3849,  0.3640, -0.3393,\n",
      "         -0.3463,  0.0815,  0.0179,  0.0869, -0.4882, -0.1310, -0.4074],\n",
      "        [-0.4519,  0.4749, -0.0961,  0.5104,  0.1004, -0.0955,  0.1699,  0.0546,\n",
      "         -0.0766, -0.2348,  0.1138,  0.1241,  0.0927,  0.0550,  0.4545]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.3615,  0.1936, -0.0135], requires_grad=True)\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "#logistic升维\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn import datasets\n",
    "import random\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import copy\n",
    "\n",
    "\n",
    "train = zipp[0:90]\n",
    "test = zipp[90:150]\n",
    "print(len(train))\n",
    "print(len(test))\n",
    "\n",
    "train = zip(*train)\n",
    "train = list(train)\n",
    "test = zip(*test)\n",
    "test = list(test)\n",
    "#print(train)\n",
    "#print('=======')\n",
    "#print(test)\n",
    "\n",
    "train_d = np.array(list(train[0]))\n",
    "train_t = np.array(list(train[1]))\n",
    "test_d = np.array(list(test[0]))\n",
    "test_t = np.array(list(test[1]))\n",
    "\n",
    "train_t1 = np.zeros([90,3])\n",
    "test_t1 = np.zeros([60,3])\n",
    "\n",
    "for i in range(90):\n",
    "    train_t1[i][train_t[i]] = 1\n",
    "    \n",
    "for i in range(60):\n",
    "    test_t1[i][test_t[i]] = 1\n",
    "    \n",
    "#print(test_t)\n",
    "#print(test_t1)\n",
    "\n",
    "ss = StandardScaler()\n",
    "zscore = ss.fit(train_d)\n",
    "train_d = zscore.transform(train_d)\n",
    "test_d = zscore.transform(test_d)\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "train_d_up = poly.fit_transform(train_d)\n",
    "test_d_up = poly.transform(test_d)\n",
    "\n",
    "feature_num = 15\n",
    "cluster_num = 3\n",
    "\n",
    "train_d = torch.from_numpy(train_d_up).float()\n",
    "train_t = torch.from_numpy(train_t).long()\n",
    "test_d = torch.from_numpy(test_d_up).float()\n",
    "test_t = torch.from_numpy(test_t).long()\n",
    "\n",
    "print(train_d.type())\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(feature_num,cluster_num),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "\n",
    "learning_rate = 0.0001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "m_acc = 0\n",
    "para = model.parameters()\n",
    "\n",
    "for t in range(30000):\n",
    "    \n",
    "    # 前向传播：通过像模型输入x计算预测的y\n",
    "    y_pred = model(train_d)\n",
    "\n",
    "    # 计算并打印loss\n",
    "    loss = loss_fn(y_pred, train_t)\n",
    "    acc = 0\n",
    "    m = torch.max(y_pred,1)\n",
    "    for j in range(90):\n",
    "        if(m[1][j] == train_t[j]): acc += 1\n",
    "            \n",
    "    \n",
    "    y_pred_test = model(test_d)\n",
    "    acc_test = 0\n",
    "    m_test = torch.max(y_pred_test,1)\n",
    "    for j in range(60):\n",
    "        if(m_test[1][j] == test_t[j]): acc_test += 1\n",
    "    \n",
    "    if acc_test > m_acc:\n",
    "        m_acc = acc_test\n",
    "        print('=====================================')\n",
    "        print('{}/{}'.format(acc,90))\n",
    "        print('{}/{}'.format(acc_test,60))\n",
    "\n",
    "        print(t, loss.item())    \n",
    "        for i in model.parameters():\n",
    "            print(i)\n",
    "        \n",
    "        print('=====================================')    \n",
    "\n",
    "    # 在反向传播之前，使用optimizer将它要更新的所有张量的梯度清零(这些张量是模型可学习的权重)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 反向传播：根据模型的参数计算loss的梯度\n",
    "    loss.backward()\n",
    "\n",
    "    # 调用Optimizer的step函数使它所有参数更新\n",
    "    optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
